# Count responses for each session length
response_counts <- data_long %>%
group_by(Session_Length, Response) %>%
summarise(Count = n(), .groups = 'drop')
# Create the bar plot
ggplot(response_counts, aes(x = Session_Length, y = Count, fill = Response)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Distribution of Attendance Likelihood by Session Length",
x = "Session Length",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
View(data_long)
data_long$Response
attendance_data <- read.csv("profdev.csv", stringsAsFactors = TRUE)[,1:3]
# Convert data to long format for easier plotting
data_long <- attendance_data %>%
tidyr::pivot_longer(cols = c(onehour, halfday, multipledays),
names_to = "Session_Length",
values_to = "Response")
data_long$Session_Length <- factor(data_long$Session_Length, levels = c("onehour", "halfday", "multipledays"))
# Count responses for each session length
response_counts <- data_long %>%
group_by(Session_Length, Response) %>%
summarise(Count = n(), .groups = 'drop')
# Create the bar plot
ggplot(response_counts, aes(x = Session_Length, y = Count, fill = Response)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Distribution of Attendance Likelihood by Session Length",
x = "Session Length",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Load necessary libraries
library(ggplot2)
library(dplyr)
# Read in the data
attendance_data <- read.csv("attendance_data.csv", stringsAsFactors = TRUE)
# Read in the data
attendance_data <- read.csv("profdev.csv", stringsAsFactors = TRUE)
# Convert data to long format for easier plotting
data_long <- attendance_data %>%
tidyr::pivot_longer(cols = c(onehour, halfday, multipledays),
names_to = "Session_Length",
values_to = "Response")
# Change the order of the session lengths
data_long$Session_Length <- factor(data_long$Session_Length, levels = c("onehour", "halfday", "multipledays"))
# Change the order of the responses
data_long$Response <- factor(data_long$Response, levels = c("I'm likely to attend", "unsure if I would attend", "I'm unlikely to attend"))
# Count responses for each session length
response_counts <- data_long %>%
group_by(Session_Length, Response) %>%
summarise(Count = n(), .groups = 'drop')
# Create the bar plot
ggplot(response_counts, aes(x = Session_Length, y = Count, fill = Response)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Distribution of Attendance Likelihood by Session Length",
x = "Session Length",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Load necessary libraries
library(ggplot2)
library(dplyr)
# Read in the data
attendance_data <- read.csv("profdev.csv", stringsAsFactors = TRUE)
# Convert data to long format for easier plotting
data_long <- attendance_data %>%
tidyr::pivot_longer(cols = c(onehour, halfday, multipledays),
names_to = "Session_Length",
values_to = "Response")
# Change the order of the session lengths
data_long$Session_Length <- factor(data_long$Session_Length, levels = c("onehour", "halfday", "multipledays"))
# Change the order of the responses
data_long$Response <- factor(data_long$Response, levels = c("I'm likely to attend", "unsure if I would attend", "I'm unlikely to attend"))
# Count responses for each session length
response_counts <- data_long %>%
group_by(Session_Length, Response) %>%
summarise(Count = n(), .groups = 'drop')
# Create the bar plot
# Create the bar plot
ggplot(response_counts, aes(x = Session_Length, y = Count, fill = Response)) +
geom_bar(stat = "identity", position = "dodge") +
scale_fill_manual(values = c("#66c2a5", "#fc8d62", "#8da0cb")) +
labs(title = "Distribution of Attendance Likelihood by Session Length",
x = "Session Length",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
activity_data <- read.csv("profdev.csv", stringsAsFactors = TRUE)
View(activity_data)
activity_data <- read.csv("profdev.csv", stringsAsFactors = TRUE)[,-c(1:3)]
View(activity_data)
unique(activity_data$CVs.and.resumes)
# Convert data to long format for easier plotting
data_long <- interest_data %>%
tidyr::pivot_longer(cols = c(CVs.and.resumes, IDPs, Software.tutorials, Funding.opportunities.and.tips, How.to.network, Conflict.resolution),
names_to = "Topic",
values_to = "Interest_Level")
interest_data <- read.csv("profdev.csv", stringsAsFactors = TRUE)[,-c(1:3)]
# Convert data to long format for easier plotting
data_long <- interest_data %>%
tidyr::pivot_longer(cols = c(CVs.and.resumes, IDPs, Software.tutorials, Funding.opportunities.and.tips, How.to.network, Conflict.resolution),
names_to = "Topic",
values_to = "Interest_Level")
# Change the order of the interest levels
data_long$Interest_Level <- factor(data_long$Interest_Level, levels = c("very interested", "mildly interested", "not interested"))
# Count interest levels for each topic
interest_counts <- data_long %>%
group_by(Topic, Interest_Level) %>%
summarise(Count = n(), .groups = 'drop')
# Sort topics by the number of "very interested" responses
sorted_topics <- interest_counts %>%
filter(Interest_Level == "very interested") %>%
arrange(desc(Count)) %>%
pull(Topic)
# Reorder topics based on the sorted order
interest_counts$Topic <- factor(interest_counts$Topic, levels = sorted_topics)
# Create the line plot
ggplot(interest_counts, aes(x = Topic, y = Count, color = Interest_Level, group = Interest_Level)) +
geom_line(size = 1.2) +
geom_point(size = 3) +
scale_color_manual(values = c("#66c2a5", "#fc8d62", "#8da0cb")) +
labs(title = "Interest Levels Across Various Topics",
x = "Topic (Sorted by Most Interested to Least Interested)",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
interest_data <- read.csv("profdev.csv", stringsAsFactors = TRUE)[,-c(1:3)]
colnames(interest_data)
# Convert data to long format for easier plotting
data_long <- interest_data %>%
tidyr::pivot_longer(cols = everything(),
names_to = "Topic",
values_to = "Interest_Level")
# Change the order of the interest levels
data_long$Interest_Level <- factor(data_long$Interest_Level, levels = c("very interested", "mildly interested", "not interested"))
# Count interest levels for each topic
interest_counts <- data_long %>%
group_by(Topic, Interest_Level) %>%
summarise(Count = n(), .groups = 'drop')
# Sort topics by the number of "very interested" responses
sorted_topics <- interest_counts %>%
filter(Interest_Level == "very interested") %>%
arrange(desc(Count)) %>%
pull(Topic)
# Reorder topics based on the sorted order
interest_counts$Topic <- factor(interest_counts$Topic, levels = sorted_topics)
# Create the line plot
ggplot(interest_counts, aes(x = Topic, y = Count, color = Interest_Level, group = Interest_Level)) +
geom_line(size = 1.2) +
geom_point(size = 3) +
scale_color_manual(values = c("#66c2a5", "#fc8d62", "#8da0cb")) +
labs(title = "Interest Levels Across Various Topics",
x = "Topic (Sorted by Most Interested to Least Interested)",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
View(interest_data)
interest_data <- read.csv("profdev.csv", stringsAsFactors = TRUE)[,-c(1:3,13)]
# Convert data to long format for easier plotting
data_long <- interest_data %>%
tidyr::pivot_longer(cols = everything(),
names_to = "Topic",
values_to = "Interest_Level")
# Change the order of the interest levels
data_long$Interest_Level <- factor(data_long$Interest_Level, levels = c("very interested", "mildly interested", "not interested"))
# Count interest levels for each topic
interest_counts <- data_long %>%
group_by(Topic, Interest_Level) %>%
summarise(Count = n(), .groups = 'drop')
# Sort topics by the number of "very interested" responses
sorted_topics <- interest_counts %>%
filter(Interest_Level == "very interested") %>%
arrange(desc(Count)) %>%
pull(Topic)
# Reorder topics based on the sorted order
interest_counts$Topic <- factor(interest_counts$Topic, levels = sorted_topics)
# Create the line plot
ggplot(interest_counts, aes(x = Topic, y = Count, color = Interest_Level, group = Interest_Level)) +
geom_line(size = 1.2) +
geom_point(size = 3) +
scale_color_manual(values = c("#66c2a5", "#fc8d62", "#8da0cb")) +
labs(title = "Interest Levels Across Various Topics",
x = "Topic (Sorted by Most Interested to Least Interested)",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
View(interest_counts)
View(interest_counts)
interest_counts <- interest_counts[!is.na(interest_counts$Topic),]
interest_counts <- interest_counts[!is.na(interest_counts$Interest_Level),]
# Sort topics by the number of "very interested" responses
sorted_topics <- interest_counts %>%
filter(Interest_Level == "very interested") %>%
arrange(desc(Count)) %>%
pull(Topic)
# Reorder topics based on the sorted order
interest_counts$Topic <- factor(interest_counts$Topic, levels = sorted_topics)
# Create the line plot
ggplot(interest_counts, aes(x = Topic, y = Count, color = Interest_Level, group = Interest_Level)) +
geom_line(size = 1.2) +
geom_point(size = 3) +
scale_color_manual(values = c("#66c2a5", "#fc8d62", "#8da0cb")) +
labs(title = "Interest Levels Across Various Topics",
x = "Topic (Sorted by Most Interested to Least Interested)",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
t.test(x=c(1,2,3), y=c(2.5,3.5,4.5), paired=T)
t.test(x=c(1,2,3), y=c(2.2,3.7,4.4), paired=T)
t.test(y=c(1,2,3), x=c(2.2,3.7,4.4), paired=T)
runApp('TA-assignments')
runApp('tester')
runApp('TA-assignments')
runApp('tester')
runApp('tester')
runApp('tester')
runApp('tester')
runApp('tester')
runApp('TA-assignments')
# Let's start by creating some basic data for a continuous response
set.seed(123)  # Set seed for reproducibility
# Create a data frame with one continuous predictor
simple_data <- data.frame(
predictor = rnorm(100, mean = 50, sd = 10)  # Predictor variable with normal distribution
)
# Create a response variable that has a true linear relationship with the predictor
simple_data$response <- 5 + 0.3 * simple_data$predictor + rnorm(100, mean = 0, sd = 2)
# Plot the data to visualize the relationship
plot(simple_data$predictor, simple_data$response,
main = "Scatterplot of Predictor vs Response",
xlab = "Predictor",
ylab = "Response")
# Fit a simple linear model using `glm`
# Note: family = gaussian() is the default for continuous response data
simple_model <- glm(response ~ predictor, data = simple_data, family = gaussian())
# Summary of the model to interpret results
summary(simple_model)
# Create a data frame with one predictor and a binary response
set.seed(456)
logistic_data <- data.frame(
predictor = rnorm(100, mean = 50, sd = 10)
)
# Create a response variable with a true logistic relationship to the predictor
logistic_data$response <- rbinom(100, 1, plogis(-50 + 0.8 * logistic_data$predictor))
# Plot the data
plot(logistic_data$predictor, logistic_data$response,
main = "Scatterplot of Predictor vs Binary Response",
xlab = "Predictor",
ylab = "Binary Response")
# Fit a logistic regression model using `glm`
# Here, we specify family = binomial() since the response is binary
logistic_model <- glm(response ~ predictor, data = logistic_data, family = binomial())
# Summary of the model to interpret the coefficients
summary(logistic_model)
# Create data with two predictors for a more complex model
set.seed(789)
complex_data <- data.frame(
predictor1 = rnorm(100, mean = 50, sd = 10),
predictor2 = rnorm(100, mean = 20, sd = 5)
)
# Create a response variable with a true logistic relationship to the predictors
complex_data$response <- rbinom(100, 1, plogis(-30 + 0.5 * complex_data$predictor1 + 0.7 * complex_data$predictor2))
# Fit a logistic regression model with two predictors
complex_model <- glm(response ~ predictor1 + predictor2, data = complex_data, family = binomial())
# Summary of the model to see the effects of each predictor
summary(complex_model)
# Adding interaction between predictor1 and predictor2
interaction_model <- glm(response ~ predictor1 * predictor2, data = complex_data, family = binomial())
# Summary to see interaction effects
summary(interaction_model)
# Create a new data frame to make predictions
new_data <- data.frame(
predictor1 = c(45, 55, 60),
predictor2 = c(15, 25, 18)
)
# Use the complex model to predict the probability of response
predictions <- predict(complex_model, newdata = new_data, type = "response")
# Show the predicted probabilities
print(predictions)
# Add fitted values to the original complex_data
complex_data$fitted <- fitted(complex_model)
# Plot fitted values against actual response using base R
plot(complex_data$predictor1, complex_data$fitted,
col = ifelse(complex_data$response == 1, "red", "blue"),
main = "Fitted Values vs Predictor 1",
xlab = "Predictor 1",
ylab = "Fitted Probability")
legend("topright", legend = c("Response = 0", "Response = 1"),
col = c("blue", "red"), pch = 1)
# Fit a logistic regression model using `glm`
# Here, we specify family = binomial() since the response is binary
logistic_model <- glm(response ~ predictor, data = logistic_data, family = binomial())
# Create a data frame with one predictor and a binary response
set.seed(456)
logistic_data <- data.frame(
predictor = rnorm(100, mean = 50, sd = 10)
)
# Create a response variable with a true logistic relationship to the predictor
logistic_data$response <- rbinom(100, 1, plogis(-50 + 0.8 * logistic_data$predictor))
# Plot the data
plot(logistic_data$predictor, logistic_data$response,
main = "Scatterplot of Predictor vs Binary Response",
xlab = "Predictor",
ylab = "Binary Response")
# Fit a logistic regression model using `glm`
# Here, we specify family = binomial() since the response is binary
logistic_model <- glm(response ~ predictor, data = logistic_data, family = binomial())
logistic_model <- glm(response ~ predictor, data = logistic_data, family = binomial)
plogis(-50 + 0.8 * logistic_data$predictor)
setwd("~/Desktop/github/coleoguy.github.io/teaching/expdes/data")
dat <-read.csv("chrysina.csv")
library(lme4)
dat <-read.csv("chrysina.csv")
fit <- lme(beyeri ~ oaks + jun + elev, random = list(~1|site, ~1|trip))
library(lme4)
dat <-read.csv("chrysina.csv")
fit <- lme(beyeri ~ oaks + jun + elev, random = list(~1|site, ~1|trip))
fit <- lmer(beyeri ~ oaks + jun + elev, random = list(~1|site, ~1|trip))
help(lme)
library(nlme)
dat <-read.csv("chrysina.csv")
fit <- lmer(beyeri ~ oaks + jun + elev, random = list(~1|site, ~1|trip))
fit <- lme(beyeri ~ oaks + jun + elev, random = list(~1|site, ~1|trip))
View(dat)
fit <- lme(beyeri ~ oaks + jun + elev, random = list(~1|site, ~1|trip), data=dat)
summary(fit)
dat <- read.csv("chrysina.csv")
View(dat)
View(dat)
colnames(dat)
fit <- lme(gloriosa ~ oaks + jun, random = list(~1|site, ~1|trip),
data = dat)
fit <- lme(dat$gloriosa ~ dat$oaks + dat$jun,
random = list(~1|dat$site, ~1|dat$trip))
summary(fit)
View(dat)
fit2 <- lme(gloriosa ~ jun,
random = list(~1|site, ~1|trip),
data = dat)
summary(fit2)
summary(fit)
summary(fit2)
colnames(dat)
fit2 <- lme(gloriosa ~ jun + date + elev,
random = list(~1|site, ~1|trip),
data = dat)
summary(fit2)
dat <- read.csv("retrogene.csv")
View(dat)
View(dat)
View(dat)
dat[3,2:11]/dat[3,12]
dat[1,2:11]/dat[1,12]
sample(1:10, size = 142, prob = dat[1,2:11]/dat[1,12])
sample(1:10, size = 142, prob = dat[1,2:11]/dat[1,12],
replace = T)
sum(sample(1:10, size = 142, prob = dat[1,2:11]/dat[1,12],
replace = T) == 2)
View(dat)
for(i in 1:1000){
parents[i] <- sum(sample(1:10, size = 142,
prob = dat[1,2:11]/dat[1,12],
replace = T) == 2)
daughters[i] <- sum(sample(1:10, size = 142,
prob = dat[2,2:11]/dat[2,12],
replace = T) == 2)
}
parents <- daughters <- c()
for(i in 1:1000){
parents[i] <- sum(sample(1:10, size = 142,
prob = dat[1,2:11]/dat[1,12],
replace = T) == 2)
daughters[i] <- sum(sample(1:10, size = 142,
prob = dat[2,2:11]/dat[2,12],
replace = T) == 2)
}
dat[3,4]
dat[3,3]
sum(parents>=45)
for(i in 1:10000){
parents[i] <- sum(sample(1:10, size = 142,
prob = dat[1,2:11]/dat[1,12],
replace = T) == 2)
daughters[i] <- sum(sample(1:10, size = 142,
prob = dat[2,2:11]/dat[2,12],
replace = T) == 2)
}
sum(parents>=45)
sum(parents>=45)/10000
sum(daughters>=40)/10000
for(i in 1:100000){
parents[i] <- sum(sample(1:10, size = 142,
prob = dat[1,2:11]/dat[1,12],
replace = T) == 2)
daughters[i] <- sum(sample(1:10, size = 142,
prob = dat[2,2:11]/dat[2,12],
replace = T) == 2)
}
.05/20
sum(parents>=45)/100000
sum(daughters>=40)/100000
sum(parents>=45)
library(evobiR)
help("SuperMatrix")
ndivs <- c()
for(i in 1:10000){
print(paste("testing",i))
hits <- 0
for(j in 1:i){
if((i %% j) == 0){
hits <- hits + 1
}
}
}
ndivs <- c()
for(i in 1:10000){
print(paste("testing",i))
hits <- 0
for(j in 1:i){
if((i %% j) == 0){
hits <- hits + 1
}
}
ndivs[i] <- hits
}
plot(ndivs)
plot(ndivs, pch=16, cex=.4)
plot(ndivs, pch=16, cex=.4, type="l")
plot(ndivs, pch=16, cex=.4)
plot(ndivs, pch=16, cex=.4, rgb=(0,0,0,.5))
plot(ndivs, pch=16, cex=.4, col=rgb(0,0,0,.5))
ndivs <- rep(0, 100000)
for(i in 1:length(ndivs)){
print(paste("testing",i))
hits <- 0
for(j in 1:i){
if((i %% j) == 0){
hits <- hits + 1
}
}
ndivs[i] <- hits
}
plot(ndivs, pch=16, cex=.4, col=rgb(0,0,0,.5))
sqrt(sd(3,4,5))
sqrt(sd(c(3,4,5)))
sqrt(sd(c(103,104,105)))
sqrt(sd(c(5,10,15)))
sqrt(sd(c(50,100,150)))
sd(c(5,10,15))/10
sd(c(50,100,150))/100
setwd("~/Downloads")
dat <- read.csv("finalchrom.csv")
dat <- read.cvs("SpeciesChromList.csv")
dat <- read.csv("SpeciesChromList.csv")
View(dat)
length(unique(dat$Name))
dat <- read.csv("coleo-2022-10-07.csv")
length(unique(dat$Name))
length(unique(dat$species))
View(dat)
length(unique(dat$name))
setwd("~/Desktop/expdesold/datasets")
dat <- read.csv("mcmc.csv")
plot(dat$p)
dat <- read.csv("mcmc.log.csv")
plot(dat$p)
plot(dat$likelihood)
dat <- read.csv("mcmc.log.file.csv")
plot(dat$likelihood)
plot(dat$p)
plot(dat$asc1)
dat <- read.csv("mcmc.log2.csv.csv")
plot(dat$p)
dat <- read.csv("mcmc.log2.csv")
plot(dat$p)
plot(dat$likelihood)
dat <- read.csv("mcmc.logfile2.csv")
plot(dat$likelihood)
plot(dat$p)
dat <- read.csv("mcmc.log2.csv")
plot(dat$p)
plot(dat$likelihood)
plot(dat$codon1)
plot(dat$codon2
)
setwd("~/Desktop/github/coleoguy.github.io/teaching/expdes/data")
dat <- read.csv("mcmc.log1.csv")
dat <- read.csv("mcmc.log1.csv")
plot(dat$)
plot(dat$likelihood)
dat <- read.csv("mcmc.log2.csv")
plot(dat$p)
t.test(dat$asc1[501:1000])
library(coda)
HPDinterval(as.mcmc(dat$asc1[501:1000]))
dat <- read.csv("mcmc.log1.csv")
View(dat)
plot(dat$likelihood)
plot(dat$likelihood,
type="l")
plot(dat$likelihood,
type="l",
ylim=c(-5200,max(dat$likelihood)))
plot(dat$likelihood,
type="l",
ylim=c(-5000,max(dat$likelihood)))
dat <- read.csv("mcmc.log2.csv")
plot(dat$p,
type="l")
View(dat)
