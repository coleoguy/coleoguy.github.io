---
title: "EXPD Cheat Sheet"
author: "Heath Blackmon"
date: "2023-11-02"
output:
  pdf_document: default
  html_document: default
---

# R Statistics Worksheet

This worksheet will guide you through performing different statistical tests in R, including T-tests (single sample, two-sample, and paired two-sample), Chi-Square test, binomial test, ANOVA, correlation, and simple Generalized Linear Models (GLMs).

Before you begin, make sure you have installed R and optionally RStudio, which is an integrated development environment for R.

## T-Tests

### Single Sample T-test

**Objective:** Test if the mean of a sample differs significantly from a known or hypothesized population mean.

```{r}
# Hypothesized population mean
mu <- 5

# Sample data
sample_data <- c(4.5, 5.1, 5.8, 4.9, 5.0, 5.3)

# Perform single sample t-test
t.test(sample_data, mu = mu)
```

### Two Sample T-test

**Objective:** Compare the means of two independent groups.

```{r}
# Group A data
group_a <- c(2.3, 2.9, 3.1, 2.8, 3.0)

# Group B data
group_b <- c(3.5, 3.8, 3.2, 3.9, 4.2)

# Perform two sample t-test
t.test(group_a, group_b)
```

### Paired Two Sample T-test

**Objective:** Compare the means of repeated measures.

```{r}
# Before intervention
before <- c(120, 112, 132, 104, 115)

# After intervention
after <- c(122, 118, 136, 108, 120)

# Perform paired two sample t-test
t.test(before, after, paired = TRUE)
```

## Chi-Square Test

**Objective:** Test for independence between categorical variables.

```{r}
# Contingency table
data <- matrix(c(10, 20, 30, 40), nrow = 2)

# Perform Chi-Square test
chisq.test(data)
```

## Binomial Test

**Objective:** Test if the probability of success in a Bernoulli experiment differs from a known probability.

```{r}
# Number of successes
x <- 5

# Number of trials
n <- 20

# Hypothesized probability of success
p <- 0.5

# Perform binomial test
binom.test(x, n, p)
```

## ANOVA

**Objective:** Compare the means of three or more groups.

```{r}
# Data for three groups
group1 <- c(6.2, 5.8, 5.9, 6.1, 6.3)
group2 <- c(6.5, 6.7, 6.8, 6.4, 6.5)
group3 <- c(5.9, 6.1, 6.0, 5.8, 6.0)

# Combine data into a data frame
df <- data.frame(values = c(group1, group2, group3),
                 group = factor(rep(c('Group1', 'Group2', 'Group3'), each = 5)))

# Perform ANOVA
res.aov <- aov(values ~ group, data = df)
summary(res.aov)
```

## Correlation

**Objective:** Measure the strength and direction of association between two continuous variables.

```{r}
# Variable X
x <- c(1, 2, 3, 4, 5)

# Variable Y
y <- c(2, 2.5, 3.5, 4.4, 5.1)

# Perform correlation test
cor.test(x, y)
```

## Simple Generalized Linear Models (GLMs)

### Linear model with discrete and continuous predictors

**Objective:** Model the relationship between a continuous response variable and predictor variables that are both discrete and continuous.

```{r}
# Binary outcome data
outcome <-    c(2, 1, 3, 1, 0, 1, 2, 5, 9, 0, 1, 10, 2, 1, 0, 1, 8, 9)

# Predictor data
predictor1 <- c(1, 3, 5, 2, 4, 0, 1, 3, 7, 2, 7, 9, 4, 6, 2, 5, 7, 8)
predictor2 <- c("A", "A", "B", "A", "A", "A", "B", "A", "B", "A", "A", "B", "A", "A", "A", "A", "B", "B")

# fit the model
model <- glm(outcome ~ predictor1 + predictor2)
summary(model)
```

### Binary Logistic Regression

**Objective:** Model the relationship between a binary response variable and one or more predictor variables.

```{r}
# Binary outcome data
outcome <-   c(0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1)

# Predictor data
predictor <- c(1, 3, 5, 2, 4, 0, 1, 3, 7, 2, 7, 9, 4, 6, 2, 5, 7, 8)

# Perform binary logistic regression
model <- glm(outcome ~ predictor, family = binomial)
summary(model)
```

### Poisson Regression

**Objective:** Model count data.

```{r}
# Count outcome data
count_data <- c(0, 2, 3, 1, 4, 13, 2, 10, 3)

# Predictor data
predictor <- c(1, 2, 3, 4, 5, 8, 2, 7, 1)

# Perform Poisson regression
model <- glm(count_data ~ predictor, family = poisson)
summary(model)
```


### Using the step function to find the best model

**Objective:** Find the "best" model.

```{r}

# create the data needed for this example
set.seed(123)
n <- 100
x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
y <- 1 + 2 * x1 + 3 * x2 + .01 * x3 + rnorm(n)
data <- data.frame(y, x1, x2, x3)

initial_model <- glm(y ~ x1 + x2 + x3, data = data)
summary(initial_model)

best_model <- step(initial_model)
summary(best_model)

```


### Monte Carlo

**Objective:** Using simulations to produce a null distribution.

```{r}
# Biological Example: Bacterial Growth Simulation

# We will simulate the growth of a bacterial population under controlled 
# conditions. The growth rate is subject to random fluctuations, but we know
# the average growth rate. We have observed our results which indicated 20
# colonies

observed <- 20
growth_rate <- 1.02  # average growth rate
time_steps <- 100   # number of time steps
n_simulations <- 1000  # number of simulations

result <- c()
set.seed(1)  # for reproducibility
for(i in 1:n_simulations){
  population <- 10
  for (t in 2:time_steps) {
        growth_factor <- rnorm(1, mean = growth_rate, sd = 0.2)
        population[t] <- population[t - 1] * growth_factor
  }
  result[i] <- population[t]
}    
  

plot(density(population))
abline(v=observed)
pval <- sum(population>=observed)/n_simulations
pval

```



### Permutation Test

**Objective:** Non-parametric approach for many problems

```{r}
# Simulating two groups of data
group_A <- rnorm(30, mean = 40, sd = 10)
group_B <- rnorm(30, mean = 55, sd = 10)
data <- data.frame(value = c(group_A, group_B), 
                   group = rep(c("A", "B"), each = 30))

n_perm <- 1000
observed_diff <- abs(mean(data$value[data$group == "A"]) - mean(data$value[data$group == "B"]))
perm_diffs <- numeric(n_perm)
for (i in 1:n_perm) {
  shuffled <- sample(data$value)
  perm_diffs[i] <- abs(mean(shuffled[data$group == "A"]) - mean(shuffled[data$group == "B"]))
}
p_value <- mean(perm_diffs >= observed_diff)
p_value
```


---

When you run these commands in R, replace the placeholder data with your actual dataset. Make sure to install any required packages and load them with `library()` if needed. For complex analyses and larger datasets, it is recommended to use appropriate data structures like data frames and to check the assumptions of each statistical test before interpreting the results.
